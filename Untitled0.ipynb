{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdvN_15gayf-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "class MySentimentModel:\n",
        "    def __init__(self):\n",
        "        self.__trainX, self.__trainY, self.__testX, self.__testY = self.__getTrainAndTestData()\n",
        "        self.__freqDict = self.__populateFrequencies()\n",
        "        self.__matrix = self.__createMatrix()\n",
        "        self.__J, self.__theta = self.__gradientDescent_algo(1e-9, 1500)\n",
        "\n",
        "    # returns training and testing data\n",
        "    @staticmethod\n",
        "    def __getTrainAndTestData():\n",
        "        positiveTweets = twitter_samples.strings('positive_tweets.json')\n",
        "        negativeTweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "        trainPos = positiveTweets[:4000]\n",
        "        trainNeg = negativeTweets[:4000]\n",
        "        testPos = positiveTweets[4000:]\n",
        "        testNeg = negativeTweets[4000:]\n",
        "\n",
        "        trainX = trainPos + trainNeg\n",
        "        testX = testPos + testNeg\n",
        "        trainY = np.append(np.ones((len(trainPos), 1)), np.zeros((len(trainNeg), 1)), axis=0)\n",
        "        testY = np.append(np.ones((len(testPos), 1)), np.zeros((len(testNeg), 1)), axis=0)\n",
        "        return trainX, trainY, testX, testY\n",
        "\n",
        "    # Cleaning, tokenizing and stemming the data\n",
        "    def __processText(self, text):\n",
        "        text = re.sub(r'^RT[\\s]+', '', text)\n",
        "        text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "        text = re.sub(r'@\\S*', '', text)\n",
        "        tokenizedText = TweetTokenizer().tokenize(text)\n",
        "        stopWords = stopwords.words('english')\n",
        "        stemmer = PorterStemmer()\n",
        "        return [stemmer.stem(word) for word in tokenizedText if word not in stopWords and\n",
        "                         word not in string.punctuation]\n",
        "\n",
        "    def __populateFrequencies(self):\n",
        "        # Gets all the positive words\n",
        "        posWords = [word for sentence in self.__trainX[:4000] for word in self.__processText(sentence)]\n",
        "        posFreq = {}\n",
        "        for word in posWords:\n",
        "            if (word, 1) not in posFreq:\n",
        "                posFreq[(word, 1)] = 1\n",
        "            else:\n",
        "                posFreq[(word, 1)] = posFreq[(word, 1)] + 1\n",
        "        # Gets all the negative words\n",
        "        negWords = [word for sentence in self.__trainX[4000:] for word in self.__processText(sentence)]\n",
        "        negFreq = {}\n",
        "        for word in negWords:\n",
        "            if (word, 0) not in negFreq:\n",
        "                negFreq[(word, 0)] = 1\n",
        "            else:\n",
        "                negFreq[(word, 0)] = negFreq[(word, 0)] + 1\n",
        "\n",
        "        frequencies = dict(posFreq)\n",
        "        frequencies.update(negFreq)\n",
        "        return frequencies\n",
        "\n",
        "\n",
        "    def __features_extraction(self, text):\n",
        "        word_l = self.__processText(text)\n",
        "        x = np.zeros((1, 3))\n",
        "        x[0,0] = 1\n",
        "        for word in word_l:\n",
        "            try:\n",
        "                x[0,1] += self.__freqDict[(word, 1)]\n",
        "            except:\n",
        "                x[0,1] += 0\n",
        "            try:\n",
        "                x[0,2] += self.__freqDict[(word, 0.0)]\n",
        "            except:\n",
        "                x[0,2] += 0\n",
        "        assert(x.shape == (1, 3))\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def __sigmoid(x):\n",
        "        h = 1/(1+np.exp(-x))\n",
        "        return h\n",
        "\n",
        "    def __gradientDescent_algo(self, alpha, num_iters):\n",
        "        theta = np.zeros((3, 1))\n",
        "        m = self.__matrix.shape[0]\n",
        "        for i in range(0, num_iters):\n",
        "            z = np.dot(self.__matrix, theta)\n",
        "            h = self.__sigmoid(z)\n",
        "            J = -1/m*(np.dot(self.__trainY.T,np.log(h))+np.dot((1-self.__trainY).T,np.log(1-h)))\n",
        "            theta = theta-(alpha/m)*np.dot(self.__matrix.T, h - self.__trainY)\n",
        "        return float(J), theta\n",
        "\n",
        "    def __createMatrix(self):\n",
        "        X = np.zeros((len(self.__trainX), 3))\n",
        "        for i in range(len(self.__trainX)):\n",
        "            X[i, :] = self.__features_extraction(self.__trainX[i])\n",
        "        return X\n",
        "\n",
        "    def compareWithNLTK(self):\n",
        "        sia = SentimentIntensityAnalyzer()\n",
        "        myScores = []\n",
        "        nltkScores = []\n",
        "        for tweet in self.__testX:\n",
        "            yPred = self.sentimentAnalysis(tweet)\n",
        "            myScores.append(yPred[0])\n",
        "            nltkScores.append(sia.polarity_scores(tweet)['compound'])\n",
        "        plt.figure()\n",
        "        plt.plot(myScores[:1000], 'o')\n",
        "        plt.plot(nltkScores[:1000], '.')\n",
        "       # plt.plot(nltkScores)\n",
        "        plt.draw()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def sentimentAnalysis(self, text):\n",
        "        x = self.__features_extraction(text)\n",
        "        sent = self.__sigmoid(np.dot(x, self.__theta))\n",
        "        return equalize(sent[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################################################################################\n",
        "############################# HELPER FUNCTIONS ##################################\n",
        "#################################################################################\n",
        "\n",
        "# Removes punctuation from a string\n",
        "def stripPunctuation(s, all=False):\n",
        "    punctuationRegex = re.compile('[{0}]'.format(re.escape(string.punctuation)))\n",
        "    return punctuationRegex.sub('', s.strip())\n",
        "\n",
        "def equalize(score):\n",
        "    if score < 0.5:\n",
        "        score = score - 1\n",
        "    return score\n",
        "#\n",
        "# # Returns a list of word tokens\n",
        "# def tokenize(text, includePunc=True):\n",
        "#     tokens = nltk.tokenize.word_tokenize(text)\n",
        "#     if includePunc:\n",
        "#         return tokens\n",
        "#     else:\n",
        "#         return [word if word.startswith(\"'\") else stripPunctuation(word, all=False)\n",
        "#                 for word in tokens if stripPunctuation(word, all=False)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('twitter_samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvk1II2-bBDD",
        "outputId": "c5bef98c-7a1e-4c42-9298-18d90c0f0f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "myModel = MySentimentModel()\n",
        "\n",
        "\n",
        "def get_scores(content):\n",
        "    myModelScores = myModel.sentimentAnalysis(content)[0]\n",
        "    sia_scores = sia.polarity_scores(content)\n",
        "\n",
        "    return pd.Series({\n",
        "        'content': content,\n",
        "        'nltk': sia_scores['compound'],\n",
        "        'my model': myModelScores,\n",
        "    })\n",
        "\n",
        "\n",
        "def main():\n",
        "    pd.set_option(\"display.max_colwidth\", 400)\n",
        "    df = pd.DataFrame({'content': [\n",
        "        \"I love love love love this kitten\",\n",
        "        \"I hate hate hate hate this keyboard\",\n",
        "        \"I'm not sure how I feel about toast\",\n",
        "        \"Did you see the world cup game yesterday?\",\n",
        "        \"The package was delivered late and the contents were broken\",\n",
        "        \"Trashy television shows are some of my favorites\",\n",
        "        \"I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\",\n",
        "        \"I find chirping birds irritating, but I know I'm not the only one\",\n",
        "        \"I do not dislike cabin cruisers\",\n",
        "        \"Disliking people is not really my thing.\",\n",
        "        \"I love love love love this kitten :)\",\n",
        "        \"I'd really truly love going out in this weather!\",\n",
        "    ]})\n",
        "    scores = df.content.apply(get_scores)\n",
        "    scores = scores.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "sCuATEiWbBtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "WBOA8vssbByD",
        "outputId": "dfd33156-fdbc-45fa-e1ab-bfe714cd8fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f8e2d5fb2b0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_0eb91_row0_col1 {\n",
              "  background-color: #75c465;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row0_col2 {\n",
              "  background-color: #bde379;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row1_col1 {\n",
              "  background-color: #f67a49;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_0eb91_row1_col2 {\n",
              "  background-color: #fdbb6c;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row2_col1 {\n",
              "  background-color: #fee999;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row2_col2 {\n",
              "  background-color: #fdb96a;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row3_col1 {\n",
              "  background-color: #fffebe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row3_col2, #T_0eb91_row4_col2, #T_0eb91_row5_col2 {\n",
              "  background-color: #c3e67d;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row4_col1 {\n",
              "  background-color: #feca79;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row5_col1 {\n",
              "  background-color: #cfeb85;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row6_col1 {\n",
              "  background-color: #fdb567;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row6_col2 {\n",
              "  background-color: #fdbf6f;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row7_col1 {\n",
              "  background-color: #fee797;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row7_col2 {\n",
              "  background-color: #fdb163;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row8_col1 {\n",
              "  background-color: #e0f295;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row8_col2 {\n",
              "  background-color: #fdbd6d;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row9_col1 {\n",
              "  background-color: #fee18d;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row9_col2 {\n",
              "  background-color: #fdc776;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row10_col1 {\n",
              "  background-color: #73c264;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row10_col2 {\n",
              "  background-color: #89cc67;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row11_col1 {\n",
              "  background-color: #8ccd67;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_0eb91_row11_col2 {\n",
              "  background-color: #c1e57b;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_0eb91_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >content</th>\n",
              "      <th class=\"col_heading level0 col1\" >nltk</th>\n",
              "      <th class=\"col_heading level0 col2\" >my model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_0eb91_row0_col0\" class=\"data row0 col0\" >I love love love love this kitten</td>\n",
              "      <td id=\"T_0eb91_row0_col1\" class=\"data row0 col1\" >0.957100</td>\n",
              "      <td id=\"T_0eb91_row0_col2\" class=\"data row0 col2\" >0.542918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_0eb91_row1_col0\" class=\"data row1 col0\" >I hate hate hate hate this keyboard</td>\n",
              "      <td id=\"T_0eb91_row1_col1\" class=\"data row1 col1\" >-0.941300</td>\n",
              "      <td id=\"T_0eb91_row1_col2\" class=\"data row1 col2\" >-0.588225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_0eb91_row2_col0\" class=\"data row2 col0\" >I'm not sure how I feel about toast</td>\n",
              "      <td id=\"T_0eb91_row2_col1\" class=\"data row2 col1\" >-0.241100</td>\n",
              "      <td id=\"T_0eb91_row2_col2\" class=\"data row2 col2\" >-0.596676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_0eb91_row3_col0\" class=\"data row3 col0\" >Did you see the world cup game yesterday?</td>\n",
              "      <td id=\"T_0eb91_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
              "      <td id=\"T_0eb91_row3_col2\" class=\"data row3 col2\" >0.508071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_0eb91_row4_col0\" class=\"data row4 col0\" >The package was delivered late and the contents were broken</td>\n",
              "      <td id=\"T_0eb91_row4_col1\" class=\"data row4 col1\" >-0.476700</td>\n",
              "      <td id=\"T_0eb91_row4_col2\" class=\"data row4 col2\" >0.501554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_0eb91_row5_col0\" class=\"data row5 col0\" >Trashy television shows are some of my favorites</td>\n",
              "      <td id=\"T_0eb91_row5_col1\" class=\"data row5 col1\" >0.421500</td>\n",
              "      <td id=\"T_0eb91_row5_col2\" class=\"data row5 col2\" >0.501132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_0eb91_row6_col0\" class=\"data row6 col0\" >I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
              "      <td id=\"T_0eb91_row6_col1\" class=\"data row6 col1\" >-0.629600</td>\n",
              "      <td id=\"T_0eb91_row6_col2\" class=\"data row6 col2\" >-0.560734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_0eb91_row7_col0\" class=\"data row7 col0\" >I find chirping birds irritating, but I know I'm not the only one</td>\n",
              "      <td id=\"T_0eb91_row7_col1\" class=\"data row7 col1\" >-0.250000</td>\n",
              "      <td id=\"T_0eb91_row7_col2\" class=\"data row7 col2\" >-0.656157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_0eb91_row8_col0\" class=\"data row8 col0\" >I do not dislike cabin cruisers</td>\n",
              "      <td id=\"T_0eb91_row8_col1\" class=\"data row8 col1\" >0.292400</td>\n",
              "      <td id=\"T_0eb91_row8_col2\" class=\"data row8 col2\" >-0.569802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_0eb91_row9_col0\" class=\"data row9 col0\" >Disliking people is not really my thing.</td>\n",
              "      <td id=\"T_0eb91_row9_col1\" class=\"data row9 col1\" >-0.318200</td>\n",
              "      <td id=\"T_0eb91_row9_col2\" class=\"data row9 col2\" >-0.506007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_0eb91_row10_col0\" class=\"data row10 col0\" >I love love love love this kitten :)</td>\n",
              "      <td id=\"T_0eb91_row10_col1\" class=\"data row10 col1\" >0.967400</td>\n",
              "      <td id=\"T_0eb91_row10_col2\" class=\"data row10 col2\" >0.846725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0eb91_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_0eb91_row11_col0\" class=\"data row11 col0\" >I'd really truly love going out in this weather!</td>\n",
              "      <td id=\"T_0eb91_row11_col1\" class=\"data row11 col1\" >0.838600</td>\n",
              "      <td id=\"T_0eb91_row11_col2\" class=\"data row11 col2\" >0.513335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRc-p0gUbB3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6TWNOekbB7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveTweets = twitter_samples.strings('positive_tweets.json')\n",
        "negativeTweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "trainPos = positiveTweets[:4000]\n",
        "trainNeg = negativeTweets[:4000]\n",
        "testPos = positiveTweets[4000:]\n",
        "testNeg = negativeTweets[4000:]\n",
        "testX = testPos + testNeg"
      ],
      "metadata": {
        "id": "lslqzQCAbB_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(testPos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A746YpE-caQL",
        "outputId": "f1cb7d89-5dd3-4047-c261-f7fcda64b605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myScores = []\n",
        "nltkScores = []\n",
        "outliers = []\n",
        "for tweet in testNeg:\n",
        "    yPred = myModel.sentimentAnalysis(tweet)\n",
        "    myScores.append(yPred[0])\n",
        "    yPred2 = sia.polarity_scores(tweet)['compound']\n",
        "    if yPred2 > 0:\n",
        "        outliers.append(tweet)\n",
        "    nltkScores.append(yPred2)\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# plt.plot(myScores[900:1100], 'o', label='my model')\n",
        "# plt.plot(nltkScores[900:1100], 's', label = 'nltk model')\n",
        "# # plt.plot(nltkScores)\n",
        "# plt.ylabel(\"Sentiment Score\")\n",
        "# plt.legend()\n",
        "# plt.draw()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "wt4kg3DZcaxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OndZGp6NhpAD",
        "outputId": "38ae57cc-3c24-4542-a0e8-976223a34e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Splendour :(',\n",
              " '@archietalanay dont be sad :(((((( ily',\n",
              " \"@RamaZafar hayeee :( hayeee :( patwari here mam but for IK's vision I would say nothing rather than a lil laugh\",\n",
              " '@TheKelseeey awhhh ok ok :( see you nalang when class opens!!! Hehe',\n",
              " \"@ryannhough I can imagine! This would shatter my dreams :-( We'll let our @CooperativeFood colleagues know all about this. ^SB\",\n",
              " 'I WANT A WHITE FRENCH BULLDOG :(((',\n",
              " 'Wanna feel loved :(',\n",
              " \"@WeeklyChris Aww Poor you T.T I wish I was there to help you. Even though I can't really help much :(\",\n",
              " '@rcdlccom hello, any info about possible interest in Jonathas ?? He is close to join Betis :( greatings',\n",
              " 'can some1 pls download smosh:the movie free online? Hahahaha :(',\n",
              " \"There's a huge bag of presents from Luke and I can't open them until he's back from work :-((((\",\n",
              " \"@rauhlstilinski I'M OMW😍 lol I wish :(((((\",\n",
              " '@lukesdagger JOKE LANG EH :( HAHDHDHSHHS',\n",
              " 'RIP TOM MOORE...... I LOVE READING HIS COMIC BOOKS....\\nANOTHER GREAT ARTIST I WILL TRULY MISS  :( http://t.co/f5uVxTUcSE',\n",
              " '@norman__g lucky spike only :-(',\n",
              " '@myungfart ella :( cheer up pls',\n",
              " '@dtaylor5633  Nothing worse :(',\n",
              " '@elglozano home dormtel near st scho!! all girls siya tho :( do you want me to help you find oneee',\n",
              " '@JDRaPlD @Excluzzive I was talking to exclusive :( U know I carry U want me to play 😘',\n",
              " 'Sharknado, one hour that I will never get back :(',\n",
              " 'Looking for fun? SNAPCHAT : LilyButle18 #snapchat #kikmenow #amateur #kikmeboys #seduce #hannibal #kiksexting :( http://t.co/y8RcKiqSZ3',\n",
              " 'when ed sheeran is preforming in your country tonight and ur not going :(',\n",
              " '@iamcharleigh_ :( have fun',\n",
              " '@HanaaGhzlli hanaaaa its your birthday???? ya Allah sorry for not wishing you in the van jn i tak tau :( happy birthday gorgeous!',\n",
              " 'What was the last present you received? — haha. basta. :( http://t.co/xhdfobhn8N',\n",
              " 'Dhis👉 @AhmedMarzooq blocked my twitter :( thank you for the good time 😢 I play 8ball,  FAKMAREY,',\n",
              " 'DCI today, now I wish I was going :-(',\n",
              " '@RCDeportivo hello, any info about possible interest in Jonathas ?? He is close to join Betis :(',\n",
              " '@1994sdork omg :-(( I LOVE YOU SO MUCH MONICA SEE YOU SOON AAAHHH !!!',\n",
              " '@JoWaltham haha. Sounds like you’re having fun and games :(',\n",
              " \"@justinbieber you don't follow me :(\",\n",
              " '@exhaustcd BUT... I HAVENT FINISHED YET :(',\n",
              " 'Kanin please :( xD',\n",
              " 'I had a dream that I met Karlie Kloss &amp; she was so so sweet &amp; she wanted to take like a bunch of goofy photos with me. :(',\n",
              " 'THEYRE SO CUTE I WISH I KNEW WHAT THEY WERE SAYING :( http://t.co/Vr3ICTaFIS',\n",
              " 'I care :( http://t.co/Oe5ID3cJIR',\n",
              " \"My grandad really isn't well :( I worry so much about him!\",\n",
              " '@jesuskylie @tothebeyhive thats not a good enough of a reason :( please dont leave youre one of my fav barbs',\n",
              " \"@LewissCharles Cooper, but I'm not convinced. Neither of your 2 please! I'm more concerned with Creasy winning Deputy - but she won't :(\",\n",
              " 'i was joking only man :(((((',\n",
              " 'What if I told u guys its my bday today ? :( all gift I want is $5 paypal',\n",
              " '@ughponcong pretty :(',\n",
              " '@DEPORSEMPRE1 hello, any info about possible interest of Jonathas ?? He is close to join Betis :( saludos',\n",
              " \"@jaydebose omfg it's the most beautiful place ever I miss it so much :(\",\n",
              " '@shagotpm ikr hais why would someone sell that precious thing? :((',\n",
              " \"Please god I don't wanna go to work :(\",\n",
              " 'Looking for fun? SNAPCHAT - JannieCam #snapchat #kikme #webcam #snapchatme #kikhorny #musicbiz #hotmusicdelocos :( http://t.co/8aOe100cdC',\n",
              " \"@LouiseMillerx @RedShoes4Life @x_Kisaragi @DayveHallam Billy did. I haven't... :(\",\n",
              " '@quidco @TPOuk would love to see acdc..missed out on tickets :(',\n",
              " '\"@Boy_Hugots: Never give up. The best things take time.\" weh :(',\n",
              " '@Shonette @HartsBakery Aw that sounds great, better than what i  have for lunch :(',\n",
              " 'I want to play the SFV!!!\\nCapcom plz :(',\n",
              " 'Tips ONLINE!\\n6/7 WINNERS yesterday!\\nJust 1 goal off a nice 20/1 :(\\nHopefully a similar strike rate today!\\nhttp://t.co/lJEB3EPZVt',\n",
              " '@phenomyoutube u probs had more fun with david than me : (',\n",
              " \"@cmoan3 don't say that :-(\",\n",
              " '@JayMcGuiness happy birthday again! And please come back to singapore :-( 😿💓💓💕😚😚😚😚😚❤️❤️❤️❤️❤️ http://t.co/5LIiqJqpBt',\n",
              " \"@kennyfairley @kevrobbo27 i don't think we will ever win the Petrofac Cup :-( ;-)\",\n",
              " 'This&gt;@AnaMyID a pathetic emotional burden.Says she likes me, cares about me, hugs me, respects me, tolerates me! &amp; calls me names too! :-(',\n",
              " \"@sxnflame I don't like dogs :(\",\n",
              " 'Guys nooooo :-( what a WOW!!!!! Wow wow wow',\n",
              " 'This boy was snapchattimg me and I was happy bc friends then he ruined it when he said \"you wanna have fun😏😏\" :((',\n",
              " 'Omfg the hugging corpses :(((((',\n",
              " '@DeEstrellados hello, any info about possible interest of Jonathas ?? Hes close to Betis :(',\n",
              " '@yuniizu LA time, right? Yes yunnie, im serious :(((',\n",
              " \"Don't spoil me :( http://t.co/XJGO5Znsjh\",\n",
              " 'when your fav cheese gives you migrines :( &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;',\n",
              " 'I wish I could be friends with everybody :( lmfaooooo',\n",
              " \"@bumkeyyfel b-butt : ( isn't black cat a bad luck ene\",\n",
              " '@21dadoongie yes hopefully next year :((',\n",
              " \"@yoditstanton @elise_huard @bodil I used to recommend East Dulwich, but it's gone super crazy in the last five years. :(\",\n",
              " 'The last few episodes were really intense :(((((( kagami n kuroko forever &lt;3',\n",
              " \"can't sleep :-(\",\n",
              " \"I just can't say nah to food :((((\",\n",
              " \"@theohurts whaaat. this so isn't fair :(\",\n",
              " '@Hafeelalala I also want :((',\n",
              " \"RIP Lola. :( I'll miss you. Sorry at di kita nadalaw the last days. Thank you for everything.. sa memories, sa warm hugs, sa lahat. Labyu la\",\n",
              " 'MY FAV EMOTICON RIGHT NOW IS THE \" :(: \" EMOTICON',\n",
              " \"I haven't been on much these past 2 days bc I need to save my 3g but I feel like I've missed tonnes :(((\",\n",
              " 'omg when ally hugs mani she wraps her arms around her neck and pulls her closer :-(((',\n",
              " \"@ConnorFranta PLEASE FOLLOW ME CONNO!!!! I'M LATE AGAIN!!! BECAUSE TIME ZONE AND I COULD FREAK OUT THAT YOU NEVER SEE ME!! :(\",\n",
              " '@iperfectyonce @justinbieber its my biggest dream can u follow me brooo :((((',\n",
              " '@waniiamira ehem 😏😏 haha ala yeke :( its okay then, have fun in kk! jumpa next time, in ✈️ or 🇺🇸 maybe😋',\n",
              " '@zayndrome i cant find it :(',\n",
              " \"I wanna cut k but I'm with my friends and they threw me a sleepover party :( so I'm pretending to be ok like usual\",\n",
              " 'And now that love island has finished I feel like summer has gone :(',\n",
              " 'I could just really use a hug and maybe some icecream :(',\n",
              " 'Want to watch paper town :-(((',\n",
              " '@denisegohemun it feels like ytd :((((((',\n",
              " \"@woIfgaang it's the story of our life :( haha look who's talking\",\n",
              " \"@SP3CTACL3S she's my friend :(\",\n",
              " \"@wajiyaamjad ok I'll write u every week :((\",\n",
              " 'okay i miss you @AnnShela_  :(( http://t.co/So3zOCWfiA',\n",
              " \"Some times I like this style :| but now I didn't liked it :( http://t.co/jjSI8VScPL\",\n",
              " '@BRATSUNITED @ShutUpPenguin @epiphanichood why did it? Lmao. I only back out if it gets really really serious....:((',\n",
              " \"PLEASE watch infinite's mv!!!!!! :(\",\n",
              " '@theresaninkspot :( Well, the cookies better be worth it',\n",
              " \"@MalcolmInx lmao if I can catch up to the point where I can watch weekly then I'll be ok with that if I make it to 700 &amp; there's 800 eps :(\",\n",
              " \"@nottswcentre Those cakes look AMAZING! Can't believe I'm missing it! :(\",\n",
              " 'have fun in Osaka, super junior!! :( it would be lovely to watch their comeback stage though',\n",
              " '@ParkSooyoungie @_allypasturan @gbrllx aytona? hala guys get ready na mathird wheel :(( jkjk',\n",
              " 'so i have to survive another week without my phone :(',\n",
              " '@JayMcGuiness please baby follow me :(((',\n",
              " \"there's nothing to do :-(\",\n",
              " \"I can't feel tomorrow :(\",\n",
              " \"@genrentuk with landlords like @RichardBenyonMP as MP's though that's not going to be easy? :-(\",\n",
              " 'Love Warrior :-(',\n",
              " \"@TotallyWonwooed lol, i'm too lazy to learn ps :((((\",\n",
              " 'Dem free tix to Big Bang concert :(',\n",
              " '@marlenejazmyne idk :-( maybe because I think boobs are more fun to play with',\n",
              " 'I need hug :(',\n",
              " \"@Worthless_Bums SM1 wasn't that bad. I mean, I only got mutilated by a robot that shot through a wall I didn't know could be destroyed...&gt;:(\",\n",
              " 'Good morning, Twitter friends! Hope you all have an amazing day! So freakin tired, need more sleep :(',\n",
              " '@Citadel_Hoju @Citadel_Carry @StubsAU @Citadel_Jimz I wish I was there to help :(',\n",
              " 'I wish Twitter would support audio recordings. I would send yall snippets, these are amazing :(',\n",
              " \"Oh am I not allowed to vote for the teen choice awards?? :(( It said I'm out of the area\",\n",
              " 'all I want is for my icon to be a selfie of Jack and I :((',\n",
              " \"@CandySalvatore you're right. I'm very tired :( good night my Ally. I love you ❤️\",\n",
              " 'i got so excited when micha rt or fave my tweet why am i such a creep :-( @japhantrash',\n",
              " '@Mursano buy me something to drank then cause we have nothing :(',\n",
              " \"i slept all day and now i can't sleep :(\",\n",
              " 'Waiting for love me recuerda tanto a Bath :((',\n",
              " '@chris_shak if it was you maybe but its not :(',\n",
              " \"@bravefrontiergl could you pls take care of the servers befor you send that? We have no value in it, as long as we can't get in :(\",\n",
              " '@KathrynLNewton my lovely baby, sweet cinnamon you are the best :(',\n",
              " '@LucyAndLydia I wish I could dm you cute things :( (preferably cute kittens and puppies)',\n",
              " '@thejcenaligway I still have to get a paper from engg then go back to cmc then OUR before maging okay :((',\n",
              " 'that\\'s kind of a dumb statement because who LIKES moodswings?? it\\'s like making a tweet saying \"I hate terminal diseases :(\" like wow unique',\n",
              " \"@KristyBookNerd Uh huh :( Two times, because I'm super clever like that\",\n",
              " 'When fave unfollows :(😩💖 @itisfurny http://t.co/hoVQLoKtIg',\n",
              " 'lrT bambam likes those sodas too :((( we were meant to be :((((',\n",
              " '@_Jazdorothy cheer up :-(',\n",
              " '@isakigoboom Payback for liking your videos and trying to help you get kit kats? :(',\n",
              " \"I'm not even tired :-(\",\n",
              " 'HAPPY BIRTHDAY BES! @mahhriel_114 Enjoy your day beb. I love you! Miss you sooooo muchie :( See you soon sana! 💞🎈🎂🎉😘 http://t.co/c5ooBR6OV9',\n",
              " 'CUTIE :((( http://t.co/XLVw7xaYSi',\n",
              " \"@annarlonsdale When she asked to go to the bathroom :-( I'm really enjoying the show though.\",\n",
              " 'ughh i got nothing but pain :(',\n",
              " \"Naw :( Deep Dreamed my novel hoping there'd be invisible page beasts scuttling around but there's just worm tracks http://t.co/feTHZT8bfs\",\n",
              " \"@sneaksontaylor no it's not :(\",\n",
              " \"@MsMeghanMakeup hope you're having fun at vidcon!! rlly bummed i couldnt go :(( love you sunshine 💛💛💛💛\",\n",
              " 'last night was so good :( 😺💒💎🎉',\n",
              " \"If you want a biscuit slathered in chocolate, it's definitely taxed. Boo. :(\",\n",
              " 'my beloved grandmother : ( https://t.co/wt4oXq5xCf',\n",
              " '#RIPRishikeshwari.\\nYour soul rest in peace.\\n:(',\n",
              " '@hyungwons_ tELL HIM TO PLS EAT MORE :-(((',\n",
              " '@CHEDA_KHAN Thats life. I get calls from people I havent seen in 20 years and its always favours : (',\n",
              " '@pipsuxx is he gonna be okay i love him :(',\n",
              " 'Last full night in Greece :( @ OPUS Inner Pleasure https://t.co/poglAQg9sJ',\n",
              " \"@nicababess it didn't work :( http://t.co/aQzxRk7nk2\",\n",
              " 'Lol just got split so hard. Lol single single split collat spilt single single spilt single split single single collat. :(',\n",
              " 'i hope you feel better, jay. :(',\n",
              " \"someone get mads a reece vm tomorrow please!!!! she's never had one :(\",\n",
              " 'Deth Deth Dont Leave Me :(',\n",
              " '@Sakib_ovi so true :-(',\n",
              " 'Can someone hug me pls? :((((((',\n",
              " '@98_madhvi_tommo  it apparently isnt :(',\n",
              " \"Best get me and my little lady out of our pj's need to go wallpaper for me mom :( really cba today\",\n",
              " '@farhainismail_ yes pls far i need it :(',\n",
              " \"@JaydnNeal1 Aw bless you, this made me smile! I'm missing you too :(\",\n",
              " 'I want my phone baaack :(((',\n",
              " '24 hours not enough :(',\n",
              " '@NicoIrishNews i wish for bloopers :((((',\n",
              " '@paigecardona $20 is nothing though :(',\n",
              " 'i want that bandana and bottle set huhuh :((',\n",
              " 'Being a pro soccer play would be so cool :(',\n",
              " '@MaddyyOR @TreqEu i Wish But b8 Too Strong :(',\n",
              " \"@ITVCentral #Midlands Yes thanks for the depressing weather forecast, where the word 'rain' was mentioned several times :-(\",\n",
              " \"@shellbryson We're sorry you feel this way Shell :( We regularly review our pricing to offer the best we can.\",\n",
              " '@Tanyastan4nicki girlll did u hear abt the possibly tsunami for us in West Indies?? Im in my island im afraid lol :((',\n",
              " 'Hulk Hogan in the news for a racial tirade :( I thought he couldnt stoop lower than his role in Thunder in Paradise http://t.co/vd0z6x8t8g',\n",
              " \"@esp__132 oh really :( i saw a few gif posts and some had seen really happy about it, but maybe it's people who'd be happy with any naruhina\",\n",
              " \"@Errata_0 you can't :(\",\n",
              " '@GFuelEnergy i want that but i dont have paypal :(',\n",
              " \"@flrsbea wow that's great! What's your username? :(\",\n",
              " 'i want durian strudel :(.',\n",
              " 'Like why did you have to join the marines? :-(',\n",
              " \"@annnalucz i'm not going :( kailan ba? may tix ka?\",\n",
              " \"@Oduun_ lmao :( most natural hair I've seen is ugly I swear\",\n",
              " '@jobhopjulie I was there on the Sunday for a little while.  Not been able to get up much this year, busy :( all looked great tho!',\n",
              " \"@aurorakween you don't fwm :(\",\n",
              " \"@denocte Thanks - lack of time is a problem, isn't it :(\",\n",
              " 'when ur cat is super nice and cuddly but then suddenly scratches and tries to bite :( \\n\\nlike who can i trust anymore',\n",
              " \"@bravefrontiergl Honestly at this point I don't care about compensation. I just want to be able to play BF again. :(\",\n",
              " '@dnwrld that song is not on here :(',\n",
              " \"I couldn't sleep last night n it didn't help me waking up at 8 this morning n my phone wasn't even charged :(\",\n",
              " 'I need to like, tell myself na, na okay lang :((((',\n",
              " 'PAP of your spirit animal? — no i dont have :( http://t.co/0UvPRQnvGl',\n",
              " '@dongvvoo1122 😀🔫 r u sure u want that b r u h we barely survive w them in tank tops :((',\n",
              " \"You guys are never on :( — Aw sorry we're really bust atm.. Shall be back soon http://t.co/YHfZFhLCgr\",\n",
              " \"@louanndavies Completely agree. The press won't :(\"]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testX[921:928])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byCqliLscrb3",
        "outputId": "5a1927f2-d5de-4472-efc9-cab19ef855f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['me: as long as i feel comfortable im gonna wear what i want\\nmy mother: haha...that sounds nice...but no :-)', '@richardosman congratulations to you daughter! :D', 'goodnight I love everyone but hate myself because in stupid :)', '@ailyngarciia Thank you for filling me in! Although my opinion still stands, BUT we can just agree to disagree, no harm done! :)', \"@StormyKittyhawk You'll see me Saturday :p I'll see you then Stormy :D\", 'Its time 2 party :D http://t.co/hjnT6v40eT', '@RblSports upgraded ans synced up. Plus it can be done from a single remote device. Getting there folks. :)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myModel.sentimentAnalysis('goodnight I love everyone but hate myself because i\\'m stupid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkvnuHZSgXEJ",
        "outputId": "b4302381-51b5-444c-e830-32e5e2467480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.55731294])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testX[1023:1027])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdFKLY0AguL8",
        "outputId": "13f2932f-9d4f-4b48-9c9b-36ca73bb17cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['@archietalanay dont be sad :(((((( ily', '@sonzhi No, I am going to spend the night in Prague and then leaving tomorrow :(', 'one of my friend is following me , a little heart attack , im sorry youre blocked :((((( sadis', \"@ellierowexo no I'm annoyed :(\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main2():\n",
        "    pd.set_option(\"display.max_colwidth\", 400)\n",
        "    df = pd.DataFrame({'content': [\n",
        "        \"RIP TOM MOORE! I LOVE READING HIS COMIC BOOKS. ANOTHER GREAT ARTIST I WILL TRULY MISS\",\n",
        "        \"dont be sad :(((((( i love you\",\n",
        "        \"i want to go back to the time where everything is still fine\",\n",
        "        \"I like your eyes :D\",\n",
        "        \"mom + :) = horror movie\",\n",
        "        \"sure...\",\n",
        "        \"I wish I was there to help :(\",\n",
        "        \"You make me suffer, You make me feel.. \\n\\nAddictive song i always sing in KARAOKE :-)\",\n",
        "    ]})\n",
        "    scores = df.content.apply(get_scores)\n",
        "    scores = scores.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "te7F0vBJiQlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "lv8z-ICsvmVR",
        "outputId": "296bac77-c24d-44aa-dbc5-ead699702cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f54577ea520>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_fb633_row0_col1 {\n",
              "  background-color: #73c264;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row0_col2 {\n",
              "  background-color: #fdb768;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row1_col1 {\n",
              "  background-color: #8ccd67;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row1_col2 {\n",
              "  background-color: #f8864f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_fb633_row2_col1 {\n",
              "  background-color: #ddf191;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row2_col2 {\n",
              "  background-color: #fdc372;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row3_col1 {\n",
              "  background-color: #8ecf67;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row3_col2 {\n",
              "  background-color: #fec877;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row4_col1 {\n",
              "  background-color: #fff0a6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row4_col2 {\n",
              "  background-color: #82c966;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row5_col1 {\n",
              "  background-color: #fdfebc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row5_col2 {\n",
              "  background-color: #fdc776;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row6_col1 {\n",
              "  background-color: #d1ec86;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row6_col2 {\n",
              "  background-color: #f67a49;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_fb633_row7_col1 {\n",
              "  background-color: #fee593;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_fb633_row7_col2 {\n",
              "  background-color: #b3df72;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_fb633_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >content</th>\n",
              "      <th class=\"col_heading level0 col1\" >nltk</th>\n",
              "      <th class=\"col_heading level0 col2\" >my model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_fb633_row0_col0\" class=\"data row0 col0\" >RIP TOM MOORE! I LOVE READING HIS COMIC BOOKS. ANOTHER GREAT ARTIST I WILL TRULY MISS</td>\n",
              "      <td id=\"T_fb633_row0_col1\" class=\"data row0 col1\" >0.897700</td>\n",
              "      <td id=\"T_fb633_row0_col2\" class=\"data row0 col2\" >-0.606285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_fb633_row1_col0\" class=\"data row1 col0\" >dont be sad :(((((( i love you</td>\n",
              "      <td id=\"T_fb633_row1_col1\" class=\"data row1 col1\" >0.775300</td>\n",
              "      <td id=\"T_fb633_row1_col2\" class=\"data row1 col2\" >-0.869361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_fb633_row2_col0\" class=\"data row2 col0\" >i want to go back to the time where everything is still fine</td>\n",
              "      <td id=\"T_fb633_row2_col1\" class=\"data row2 col1\" >0.273200</td>\n",
              "      <td id=\"T_fb633_row2_col2\" class=\"data row2 col2\" >-0.538241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_fb633_row3_col0\" class=\"data row3 col0\" >I like your eyes :D</td>\n",
              "      <td id=\"T_fb633_row3_col1\" class=\"data row3 col1\" >0.760300</td>\n",
              "      <td id=\"T_fb633_row3_col2\" class=\"data row3 col2\" >-0.501075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_fb633_row4_col0\" class=\"data row4 col0\" >mom + :) = horror movie</td>\n",
              "      <td id=\"T_fb633_row4_col1\" class=\"data row4 col1\" >-0.177900</td>\n",
              "      <td id=\"T_fb633_row4_col2\" class=\"data row4 col2\" >0.822836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_fb633_row5_col0\" class=\"data row5 col0\" >sure...</td>\n",
              "      <td id=\"T_fb633_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
              "      <td id=\"T_fb633_row5_col2\" class=\"data row5 col2\" >-0.505224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_fb633_row6_col0\" class=\"data row6 col0\" >I wish I was there to help :(</td>\n",
              "      <td id=\"T_fb633_row6_col1\" class=\"data row6 col1\" >0.361200</td>\n",
              "      <td id=\"T_fb633_row6_col2\" class=\"data row6 col2\" >-0.926010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_fb633_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_fb633_row7_col0\" class=\"data row7 col0\" >You make me suffer, You make me feel.. \n",
              "\n",
              "Addictive song i always sing in KARAOKE :-)</td>\n",
              "      <td id=\"T_fb633_row7_col1\" class=\"data row7 col1\" >-0.296000</td>\n",
              "      <td id=\"T_fb633_row7_col2\" class=\"data row7 col2\" >0.560603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rtQprJC57b1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}